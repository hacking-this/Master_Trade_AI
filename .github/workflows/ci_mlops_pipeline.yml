name: AI Stock Pipeline CI/CD and Daily MLOps Run

on:
  # 1. Trigger on Push (for CI/CD checks)
  push:
    branches:
      - main
      
  # 2. Trigger on Schedule (The MLOps Scheduler)
  schedule:
    # Runs the pipeline daily at 00:30 UTC (approx. 6:00 AM IST)
    - cron: '30 0 * * *' 

jobs:
  # Job 1: Build & Push the Docker Image (Runs on Code Push)
  build_and_push_docker:
    # This job only runs when you push code
    if: github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }} 

      - name: Set up Docker Buildx
        # Use the most stable version 3 for setup
        uses: docker/setup-buildx-action@v3

      - name: Build and push MLOps image
        # Use the stable version 5 for the build
        uses: docker/build-and-push-action@v5
        with:
          context: .
          push: true
          # This syntax is now correct as your repository name is lowercase
          tags: ghcr.io/${{ github.repository }}/master-trader-airflow:latest
          file: ./Dockerfile

  # Job 2: Run the Live MLOps Pipeline (Runs Daily)
  run_daily_pipeline:
    # This job only runs on the 'schedule' trigger
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python 3.9
        uses: actions/setup-python@v3
        with:
          python-version: '3.9'
          
      - name: Install All Python Dependencies
        run: pip install -r requirements.txt
        
      - name: Run Full MLOps Pipeline
        # Inject the cloud database URL from GitHub Secrets
        env:
          DATABASE_URL: ${{ secrets.RENDER_DB_URL }} 
        run: |
          echo "Starting Daily Pipeline Run..."
          
          # Task 1: Ingest Data (Watermarked)
          python scripts/ingestion/ingest_data.py
          
          # Task 2: Feature Engineering (WFO Features)
          python scripts/features/transform_features.py
          
          # Task 3: AI Training (WFO Model)
          python scripts/ai/train_ai_model.py
          
          echo "MLOps Pipeline run completed successfully."